{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZUspOG6zzHJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN2PagvUINI-",
        "outputId": "7bb2b70f-fb8d-4a62-859c-6e67e2badf8b"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "#load dataset\n",
        "(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "#load train and test dataset\n",
        "def load_dataset():\n",
        "    #load dataset\n",
        "    (trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "    #reshape dataset to have a single channel\n",
        "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "    testX = testX.reshape((test.shape[0], 28, 28, 1))\n",
        "    trainY = to_categorical(trainY)\n",
        "    testY = to_categorical(testY)\n",
        "    return trainX, trainY, testX, testY\n",
        "    \n",
        "\n",
        "seed = 9\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "data_split = StratifiedShuffleSplit(test_size = 0.5,random_state = seed)\n",
        "for train_index, test_index in data_split.split(trainX, trainY):\n",
        "    \n",
        "    split_data_92, split_data_8 = trainX[train_index], trainX[test_index]\n",
        "    \n",
        "    split_label_92, split_label_8 = trainY[train_index], trainY[test_index]\n",
        "train_test_split = StratifiedShuffleSplit(test_size = 0.3,random_state = seed)\n",
        "\n",
        "#data splitting\n",
        "for train_index, test_index in train_test_split.split(split_data_8,split_label_8):\n",
        "    \n",
        "    train_data_70, test_data_30 = split_data_8[train_index], split_data_8[test_index]\n",
        "    \n",
        "    train_label_70, test_label_30 = split_label_8[train_index], split_label_8[test_index]\n",
        "train_data = train_data_70\n",
        "\n",
        "train_labels = train_label_70\n",
        "\n",
        "test_data = test_data_30\n",
        "\n",
        "test_labels = test_label_30\n",
        "print('train_data : ',train_data.shape)\n",
        "print('train_labels : ',train_labels.shape)\n",
        "print('test_data : ',test_data.shape)\n",
        "print('test_labels : ',test_labels.shape)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#data preprocessing\n",
        "#PREPROCESSING WITH NORMALIZATION FUNCTION\n",
        "def normalize(data, eps=1e-8):\n",
        "    data -= data.mean(axis=(0,1,2),keepdims=True)\n",
        "    std = np.sqrt(data.var(axis=(0, 1, 2), ddof=1, keepdims=True))\n",
        "    std[std < eps] = 1\n",
        "    data /= std\n",
        "    return data\n",
        "train_data=train_data.astype('float64')\n",
        "test_data=test_data.astype('float64')\n",
        "#calling the function\n",
        "train_data = normalize(train_data)\n",
        "test_data = normalize(test_data)\n",
        "#printing the slope of train data and test data\n",
        "print('train_data: ', train_data.shape)\n",
        "print('test_data: ',test_data.shape)\n",
        "\n",
        "\n",
        "#PREPROCESSING WITH PCA\n",
        "#computing whitening matrix\n",
        "train_data_flat = train_data.reshape(train_data.shape[0], -1)\n",
        "test_data_flat = test_data.reshape(test_data.shape[0], -1)\n",
        "print('train_data_flat: ',train_data_flat.shape)\n",
        "print('test_data_flat: ',test_data_flat.shape)\n",
        "\n",
        "train_data_flat_t = train_data_flat\n",
        "test_data_flat_t = test_data_flat\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "train_data_pca =PCA(n_components=min(train_data_flat.shape)).fit_transform(train_data_flat)\n",
        "test_data_pca =PCA(n_components=min(test_data_flat.shape)).fit_transform(test_data_flat)\n",
        "print(train_data_pca.shape)\n",
        "print(test_data_pca.shape)\n",
        "\n",
        "\n",
        "#PREPROCESSING WITH SVD\n",
        "from skimage import color\n",
        "\n",
        "def svdFeatures(input_data):\n",
        "    svdArray_input_data=[]\n",
        "    size = input_data.shape[0]\n",
        "    for i in range (0,size):\n",
        "        img=color.rgb2gray(input_data[i])\n",
        "        u, s, v = np.linalg.svd(img, full_matrices=False)\n",
        "        S=[s[i] for i in range(28)]\n",
        "        svdArray_input_data.append(S)\n",
        "        svdMatrix_input_data=np.matrix(svdArray_input_data)\n",
        "    return svdMatrix_input_data\n",
        "#apply SVD for train and test data\n",
        "train_data_svd=svdFeatures(train_data)\n",
        "test_data_svd=svdFeatures(test_data)\n",
        "print(train_data_svd.shape)\n",
        "print(test_data_svd.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "train_data :  (21000, 28, 28)\n",
            "train_labels :  (21000,)\n",
            "test_data :  (9000, 28, 28)\n",
            "test_labels :  (9000,)\n",
            "train_data:  (21000, 28, 28)\n",
            "test_data:  (9000, 28, 28)\n",
            "train_data_flat:  (21000, 784)\n",
            "test_data_flat:  (9000, 784)\n",
            "(21000, 784)\n",
            "(9000, 784)\n",
            "(21000, 28)\n",
            "(9000, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3d4SrR20kiZ"
      },
      "source": [
        "#By using data preprocessed with NORMALIZATION FUNCTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUYj2zCqaNNS",
        "outputId": "a87cfdec-9364-4ff6-e43e-74695ffa8dc3"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "MLP1=MLPClassifier()\n",
        "MLP1.fit(train_data_flat_t,train_labels)\n",
        "\n",
        "mlp_predict1 = MLP1.predict(test_data_flat_t)\n",
        "score1 = MLP1.score(test_data_flat_t,test_labels)\n",
        "print(\"score\", score1)\n",
        "\n",
        "Confusion_Matrix1 = metrics.confusion_matrix(test_labels, mlp_predict1)\n",
        "print(\"Confusion Matrix\",Confusion_Matrix1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score 0.8735555555555555\n",
            "Confusion Matrix [[717   5  26  28   4   2 111   1   6   0]\n",
            " [  2 878   3  13   0   0   3   0   1   0]\n",
            " [  8   1 733   6  79   1  69   1   2   0]\n",
            " [ 23  10  17 786  34   0  30   0   0   0]\n",
            " [  1   2  79  23 716   0  74   0   5   0]\n",
            " [  0   0   1   1   0 853   1  27   2  15]\n",
            " [128   3  64  22  48   0 621   1  12   1]\n",
            " [  0   0   0   0   0  22   0 860   2  16]\n",
            " [ 11   0   4   4   7   9   8   3 853   1]\n",
            " [  0   1   0   1   0   9   0  44   0 845]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM3yKS6y0p7D"
      },
      "source": [
        "#By using data preprocessed with PCA "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXTWratKfXAA",
        "outputId": "2173e678-4b10-484e-aefe-d8b25a42c885"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "MLP2=MLPClassifier()\n",
        "MLP2.fit(train_data_pca,train_labels)\n",
        "\n",
        "mlp_predict2 = MLP2.predict(test_data_pca)\n",
        "score2 = MLP2.score(test_data_pca,test_labels)\n",
        "print(\"score\", score2)\n",
        "\n",
        "Confusion_Matrix2 = metrics.confusion_matrix(test_labels, mlp_predict2)\n",
        "print(\"Confusion Matrix\",Confusion_Matrix2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score 0.30955555555555553\n",
            "Confusion Matrix [[571  16  71  40  28  14 134   8   7  11]\n",
            " [ 29 555  20 280   5   2   4   0   5   0]\n",
            " [110  22 105  27 166  62  62   7 209 130]\n",
            " [133  55 206 285 142  10  61   2   1   5]\n",
            " [ 61  26 115  42 292  19 105   4 143  93]\n",
            " [  4   6   2   5  15 356  43 260  97 112]\n",
            " [225  19 104  32 114  49 139   5  68 145]\n",
            " [  3  15   4   0   8 247   5 310 266  42]\n",
            " [ 11  22  67   9  60  94  80  91 149 317]\n",
            " [  0   0  26   0  77 346 146  55 226  24]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-0VbBry0wGT"
      },
      "source": [
        "#By using data preprocessed with SVD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k7W3ejjf9On",
        "outputId": "a553d1d7-271d-4534-96b3-c9b6f99afa85"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "MLP3=MLPClassifier()\n",
        "MLP3.fit(train_data_svd,train_labels)\n",
        "\n",
        "mlp_predict3 = MLP3.predict(test_data_svd)\n",
        "score3 = MLP3.score(test_data_svd,test_labels)\n",
        "print(\"score\", score3)\n",
        "\n",
        "Confusion_Matrix3 = metrics.confusion_matrix(test_labels, mlp_predict3)\n",
        "print(\"Confusion Matrix\",Confusion_Matrix3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score 0.6016666666666667\n",
            "Confusion Matrix [[500   9  29  85  59  10 110   8  52  38]\n",
            " [  9 704   3  87   5  22   4  59   5   2]\n",
            " [ 59   0 397  12 158  10 196   2  58   8]\n",
            " [ 40 192  12 406  81  48  35  48  28  10]\n",
            " [ 43   7  88  67 496   7 145   6  35   6]\n",
            " [ 12  15   0  21   7 659  38  89  30  29]\n",
            " [158   3  81  50 136  26 360   2  76   8]\n",
            " [  6  38   0  24   0  81   1 591  10 149]\n",
            " [ 93   8  26  56  52  30  55  17 506  57]\n",
            " [ 35   1   1   1   5  12   5  31  13 796]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}