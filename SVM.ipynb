{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN2PagvUINI-",
        "outputId": "b9989114-69ad-4b7d-8d6f-ce0d7f00751f"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "#load dataset\n",
        "(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "#load train and test dataset\n",
        "def load_dataset():\n",
        "    #load dataset\n",
        "    (trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "    #reshape dataset to have a single channel\n",
        "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "    testX = testX.reshape((test.shape[0], 28, 28, 1))\n",
        "    trainY = to_categorical(trainY)\n",
        "    testY = to_categorical(testY)\n",
        "    return trainX, trainY, testX, testY\n",
        "    \n",
        "\n",
        "seed = 9\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "data_split = StratifiedShuffleSplit(test_size = 0.5,random_state = seed)\n",
        "for train_index, test_index in data_split.split(trainX, trainY):\n",
        "    \n",
        "    split_data_92, split_data_8 = trainX[train_index], trainX[test_index]\n",
        "    \n",
        "    split_label_92, split_label_8 = trainY[train_index], trainY[test_index]\n",
        "train_test_split = StratifiedShuffleSplit(test_size = 0.3,random_state = seed)\n",
        "\n",
        "#data splitting\n",
        "for train_index, test_index in train_test_split.split(split_data_8,split_label_8):\n",
        "    \n",
        "    train_data_70, test_data_30 = split_data_8[train_index], split_data_8[test_index]\n",
        "    \n",
        "    train_label_70, test_label_30 = split_label_8[train_index], split_label_8[test_index]\n",
        "train_data = train_data_70\n",
        "\n",
        "train_labels = train_label_70\n",
        "\n",
        "test_data = test_data_30\n",
        "\n",
        "test_labels = test_label_30\n",
        "print('train_data : ',train_data.shape)\n",
        "print('train_labels : ',train_labels.shape)\n",
        "print('test_data : ',test_data.shape)\n",
        "print('test_labels : ',test_labels.shape)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#data preprocessing\n",
        "#definition of normalization function\n",
        "def normalize(data, eps=1e-8):\n",
        "    data -= data.mean(axis=(0,1,2),keepdims=True)\n",
        "    std = np.sqrt(data.var(axis=(0, 1, 2), ddof=1, keepdims=True))\n",
        "    std[std < eps] = 1\n",
        "    data /= std\n",
        "    return data\n",
        "train_data=train_data.astype('float64')\n",
        "test_data=test_data.astype('float64')\n",
        "#calling the function\n",
        "train_data = normalize(train_data)\n",
        "test_data = normalize(test_data)\n",
        "#printing the slope of train data and test data\n",
        "print('train_data: ', train_data.shape)\n",
        "print('test_data: ',test_data.shape)\n",
        "\n",
        "#computing whitening matrix\n",
        "train_data_flat = train_data.reshape(train_data.shape[0], -1).T\n",
        "test_data_flat = test_data.reshape(test_data.shape[0], -1).T\n",
        "print('train_data_flat: ',train_data_flat.shape)\n",
        "print('test_data_flat: ',test_data_flat.shape)\n",
        "\n",
        "train_data_flat_t = train_data_flat.T\n",
        "test_data_flat = test_data_flat.T\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#preprocessing with PCA\n",
        "train_data_pca =PCA(n_components=min(train_data_flat.shape)).fit_transform(train_data_flat)\n",
        "test_data_pca =PCA(n_components=min(test_data_flat.shape)).fit_transform(test_data_flat)\n",
        "print(train_data_pca.shape)\n",
        "print(test_data_pca.shape)\n",
        "\n",
        "\n",
        "from skimage import color\n",
        "\n",
        "def svdFeatures(input_data):\n",
        "    svdArray_input_data=[]\n",
        "    size = input_data.shape[0]\n",
        "    for i in range (0,size):\n",
        "        img=color.rgb2gray(input_data[i])\n",
        "        u, s, v = np.linalg.svd(img, full_matrices=False)\n",
        "        S=[s[i] for i in range(28)]\n",
        "        svdArray_input_data.append(5)\n",
        "        svdMatrix_input_data=np.matrix(svdArray_input_data)\n",
        "    return svdMatrix_input_data\n",
        "#apply SVD for train and test data\n",
        "train_data_svd=svdFeatures(train_data)\n",
        "test_data_svd=svdFeatures(test_data)\n",
        "print(train_data_svd.shape)\n",
        "print(test_data_svd.shape)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "train_data :  (21000, 28, 28)\n",
            "train_labels :  (21000,)\n",
            "test_data :  (9000, 28, 28)\n",
            "test_labels :  (9000,)\n",
            "train_data:  (21000, 28, 28)\n",
            "test_data:  (9000, 28, 28)\n",
            "train_data_flat:  (784, 21000)\n",
            "test_data_flat:  (784, 9000)\n",
            "(784, 784)\n",
            "(9000, 784)\n",
            "(1, 21000)\n",
            "(1, 9000)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}