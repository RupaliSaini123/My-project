{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN2PagvUINI-",
        "outputId": "e991d44c-37d2-44b8-c36d-0cb6c7a30f56"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "#load dataset\n",
        "(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "#load train and test dataset\n",
        "def load_dataset():\n",
        "    #load dataset\n",
        "    (trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "    #reshape dataset to have a single channel\n",
        "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "    testX = testX.reshape((test.shape[0], 28, 28, 1))\n",
        "    trainY = to_categorical(trainY)\n",
        "    testY = to_categorical(testY)\n",
        "    return trainX, trainY, testX, testY\n",
        "    \n",
        "\n",
        "seed = 9\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "data_split = StratifiedShuffleSplit(test_size = 0.5,random_state = seed)\n",
        "for train_index, test_index in data_split.split(trainX, trainY):\n",
        "    \n",
        "    split_data_92, split_data_8 = trainX[train_index], trainX[test_index]\n",
        "    \n",
        "    split_label_92, split_label_8 = trainY[train_index], trainY[test_index]\n",
        "train_test_split = StratifiedShuffleSplit(test_size = 0.3,random_state = seed)\n",
        "\n",
        "#data splitting\n",
        "for train_index, test_index in train_test_split.split(split_data_8,split_label_8):\n",
        "    \n",
        "    train_data_70, test_data_30 = split_data_8[train_index], split_data_8[test_index]\n",
        "    \n",
        "    train_label_70, test_label_30 = split_label_8[train_index], split_label_8[test_index]\n",
        "train_data = train_data_70\n",
        "\n",
        "train_labels = train_label_70\n",
        "\n",
        "test_data = test_data_30\n",
        "\n",
        "test_labels = test_label_30\n",
        "print('train_data : ',train_data.shape)\n",
        "print('train_labels : ',train_labels.shape)\n",
        "print('test_data : ',test_data.shape)\n",
        "print('test_labels : ',test_labels.shape)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#data preprocessing\n",
        "#PREPROCESSING WITH NORMALIZATION FUNCTION\n",
        "def normalize(data, eps=1e-8):\n",
        "    data -= data.mean(axis=(0,1,2),keepdims=True)\n",
        "    std = np.sqrt(data.var(axis=(0, 1, 2), ddof=1, keepdims=True))\n",
        "    std[std < eps] = 1\n",
        "    data /= std\n",
        "    return data\n",
        "train_data=train_data.astype('float64')\n",
        "test_data=test_data.astype('float64')\n",
        "#calling the function\n",
        "train_data = normalize(train_data)\n",
        "test_data = normalize(test_data)\n",
        "#printing the slope of train data and test data\n",
        "print('train_data: ', train_data.shape)\n",
        "print('test_data: ',test_data.shape)\n",
        "\n",
        "\n",
        "#PREPROCESSING WITH PCA\n",
        "#computing whitening matrix\n",
        "train_data_flat = train_data.reshape(train_data.shape[0], -1)\n",
        "test_data_flat = test_data.reshape(test_data.shape[0], -1)\n",
        "print('train_data_flat: ',train_data_flat.shape)\n",
        "print('test_data_flat: ',test_data_flat.shape)\n",
        "\n",
        "train_data_flat_t = train_data_flat\n",
        "test_data_flat_t = test_data_flat\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "train_data_pca =PCA(n_components=min(train_data_flat.shape)).fit_transform(train_data_flat)\n",
        "test_data_pca =PCA(n_components=min(test_data_flat.shape)).fit_transform(test_data_flat)\n",
        "print(train_data_pca.shape)\n",
        "print(test_data_pca.shape)\n",
        "\n",
        "\n",
        "#PREPROCESSING WITH SVD\n",
        "from skimage import color\n",
        "\n",
        "def svdFeatures(input_data):\n",
        "    svdArray_input_data=[]\n",
        "    size = input_data.shape[0]\n",
        "    for i in range (0,size):\n",
        "        img=color.rgb2gray(input_data[i])\n",
        "        u, s, v = np.linalg.svd(img, full_matrices=False)\n",
        "        S=[s[i] for i in range(28)]\n",
        "        svdArray_input_data.append(S)\n",
        "        svdMatrix_input_data=np.matrix(svdArray_input_data)\n",
        "    return svdMatrix_input_data\n",
        "#apply SVD for train and test data\n",
        "train_data_svd=svdFeatures(train_data)\n",
        "test_data_svd=svdFeatures(test_data)\n",
        "print(train_data_svd.shape)\n",
        "print(test_data_svd.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "train_data :  (21000, 28, 28)\n",
            "train_labels :  (21000,)\n",
            "test_data :  (9000, 28, 28)\n",
            "test_labels :  (9000,)\n",
            "train_data:  (21000, 28, 28)\n",
            "test_data:  (9000, 28, 28)\n",
            "train_data_flat:  (21000, 784)\n",
            "test_data_flat:  (9000, 784)\n",
            "(21000, 784)\n",
            "(9000, 784)\n",
            "(21000, 28)\n",
            "(9000, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "699PZmBj1KgW"
      },
      "source": [
        "#By using data preprocessed with NORMALIZATION FUNCTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNfy7eIu7MfE",
        "outputId": "97164c3d-d659-4b36-b097-edc66ff7a207"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "clf1 = svm.SVC(gamma=0.001,probability=True)\n",
        "clf1.fit(train_data_flat_t, train_labels)\n",
        "\n",
        "predicted1=clf1.predict(test_data_flat_t)\n",
        "score1= clf1.score(test_data_flat_t,test_labels)\n",
        "print(\"score\",score1)\n",
        "\n",
        "Confusion_Matrix1 = metrics.confusion_matrix(test_labels, predicted1)\n",
        "print(\"Confusion Matrix\",Confusion_Matrix1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score 0.8675555555555555\n",
            "Confusion Matrix [[747   0  16  48   3   1  77   0   8   0]\n",
            " [  7 864   1  23   1   0   4   0   0   0]\n",
            " [ 12   0 700   7  99   1  75   0   6   0]\n",
            " [ 37   5   9 797  33   0  17   0   2   0]\n",
            " [  0   1  73  34 726   0  63   0   3   0]\n",
            " [  0   0   0   1   0 859   0  29   0  11]\n",
            " [168   1  76  27  59   1 555   0  13   0]\n",
            " [  0   0   0   0   0  22   0 840   2  36]\n",
            " [  2   0   2   4   2   3  20   3 864   0]\n",
            " [  1   0   1   0   0   6   0  36   0 856]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNl23b7Y1fO6"
      },
      "source": [
        "#By using data preprocessed with PCA "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FaNfHUaA0uN",
        "outputId": "2676fce4-71d8-48bc-f112-7dfddd73b5a0"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "clf2 = svm.SVC(gamma=0.001,probability=True)\n",
        "clf2.fit(train_data_pca, train_labels)\n",
        "\n",
        "predicted2=clf2.predict(test_data_pca)\n",
        "score2= clf2.score(test_data_pca,test_labels)\n",
        "print(\"score\",score2)\n",
        "\n",
        "Confusion_Matrix2 = confusion_matrix(test_labels, predicted2)\n",
        "print(\"Confusion Matrix\",Confusion_Matrix2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score 0.387\n",
            "Confusion Matrix [[644  41  29  69  16   4  72   3  13   9]\n",
            " [ 16 579   6 290   1   1   1   0   6   0]\n",
            " [ 58   0 159  59 171   6  82  13 179 173]\n",
            " [115  65  83 487 108   1  37   0   3   1]\n",
            " [ 22   5 171  64 251   4 158   3 124  98]\n",
            " [  0   0   0   1   1 261   6 529  94   8]\n",
            " [201  19 102  79  93   7 167  14  69 149]\n",
            " [  0   0   1   0   0 183   0 615 101   0]\n",
            " [ 28   0 111  11  54  98  39  83 320 156]\n",
            " [  0   0  21   0  40 324  40  11 464   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jBrgVBx1qNb"
      },
      "source": [
        "#By using data preprocessed with SVD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHuO5YpK91X-",
        "outputId": "a51fe4ae-fddc-46a8-ecd6-167cfffd4266"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "clf3 = svm.SVC(gamma=0.001,probability=True)\n",
        "clf3.fit(train_data_svd, train_labels)\n",
        "\n",
        "predicted3=clf3.predict(test_data_svd)\n",
        "score3= clf3.score(test_data_svd,test_labels)\n",
        "print(\"score\",score3)\n",
        "\n",
        "Confusion_Matrix3 = metrics.confusion_matrix(test_labels, predicted3)\n",
        "print(\"Confusion Matrix\",Confusion_Matrix3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score 0.4908888888888889\n",
            "Confusion Matrix [[311  38  22  62  62  54 146 115  39  51]\n",
            " [  8 681   6  42  18  76   3  61   2   3]\n",
            " [ 30  11 316  49 169 103 149  18  45  10]\n",
            " [ 33 297  39 167  86 117  20  88  41  12]\n",
            " [ 35  29 121  48 377  98  74  50  52  16]\n",
            " [  2  54   1   4   4 696  30  82   4  23]\n",
            " [ 87  14 125  59 118 126 225  44  88  14]\n",
            " [ 21  67   0  19   3 155   4 476   6 149]\n",
            " [ 51  24  20  76  38 101  43  65 400  82]\n",
            " [ 38   0   0   0   5  31   6  37  14 769]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}