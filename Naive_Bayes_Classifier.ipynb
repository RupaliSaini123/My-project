{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive Bayes Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUz8eoPz0O3O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN2PagvUINI-",
        "outputId": "c8c4df4e-9eb0-4672-854f-78f46af1d9ea"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "#load dataset\n",
        "(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "#load train and test dataset\n",
        "def load_dataset():\n",
        "    #load dataset\n",
        "    (trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "    #reshape dataset to have a single channel\n",
        "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "    testX = testX.reshape((test.shape[0], 28, 28, 1))\n",
        "    trainY = to_categorical(trainY)\n",
        "    testY = to_categorical(testY)\n",
        "    return trainX, trainY, testX, testY\n",
        "    \n",
        "\n",
        "seed = 9\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "data_split = StratifiedShuffleSplit(test_size = 0.5,random_state = seed)\n",
        "for train_index, test_index in data_split.split(trainX, trainY):\n",
        "    \n",
        "    split_data_92, split_data_8 = trainX[train_index], trainX[test_index]\n",
        "    \n",
        "    split_label_92, split_label_8 = trainY[train_index], trainY[test_index]\n",
        "train_test_split = StratifiedShuffleSplit(test_size = 0.3,random_state = seed)\n",
        "\n",
        "#data splitting\n",
        "for train_index, test_index in train_test_split.split(split_data_8,split_label_8):\n",
        "    \n",
        "    train_data_70, test_data_30 = split_data_8[train_index], split_data_8[test_index]\n",
        "    \n",
        "    train_label_70, test_label_30 = split_label_8[train_index], split_label_8[test_index]\n",
        "train_data = train_data_70\n",
        "\n",
        "train_labels = train_label_70\n",
        "\n",
        "test_data = test_data_30\n",
        "\n",
        "test_labels = test_label_30\n",
        "print('train_data : ',train_data.shape)\n",
        "print('train_labels : ',train_labels.shape)\n",
        "print('test_data : ',test_data.shape)\n",
        "print('test_labels : ',test_labels.shape)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#data preprocessing\n",
        "#PREPROCESSING WITH NORMALIZATION FUNCTION\n",
        "def normalize(data, eps=1e-8):\n",
        "    data -= data.mean(axis=(0,1,2),keepdims=True)\n",
        "    std = np.sqrt(data.var(axis=(0, 1, 2), ddof=1, keepdims=True))\n",
        "    std[std < eps] = 1\n",
        "    data /= std\n",
        "    return data\n",
        "train_data=train_data.astype('float64')\n",
        "test_data=test_data.astype('float64')\n",
        "#calling the function\n",
        "train_data = normalize(train_data)\n",
        "test_data = normalize(test_data)\n",
        "#printing the slope of train data and test data\n",
        "print('train_data: ', train_data.shape)\n",
        "print('test_data: ',test_data.shape)\n",
        "\n",
        "\n",
        "#PREPROCESSING WITH PCA\n",
        "#computing whitening matrix\n",
        "train_data_flat = train_data.reshape(train_data.shape[0], -1)\n",
        "test_data_flat = test_data.reshape(test_data.shape[0], -1)\n",
        "print('train_data_flat: ',train_data_flat.shape)\n",
        "print('test_data_flat: ',test_data_flat.shape)\n",
        "\n",
        "train_data_flat_t = train_data_flat\n",
        "test_data_flat_t = test_data_flat\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "train_data_pca =PCA(n_components=min(train_data_flat.shape)).fit_transform(train_data_flat)\n",
        "test_data_pca =PCA(n_components=min(test_data_flat.shape)).fit_transform(test_data_flat)\n",
        "print(train_data_pca.shape)\n",
        "print(test_data_pca.shape)\n",
        "\n",
        "\n",
        "#PREPROCESSING WITH SVD\n",
        "from skimage import color\n",
        "\n",
        "def svdFeatures(input_data):\n",
        "    svdArray_input_data=[]\n",
        "    size = input_data.shape[0]\n",
        "    for i in range (0,size):\n",
        "        img=color.rgb2gray(input_data[i])\n",
        "        u, s, v = np.linalg.svd(img, full_matrices=False)\n",
        "        S=[s[i] for i in range(28)]\n",
        "        svdArray_input_data.append(S)\n",
        "        svdMatrix_input_data=np.matrix(svdArray_input_data)\n",
        "    return svdMatrix_input_data\n",
        "#apply SVD for train and test data\n",
        "train_data_svd=svdFeatures(train_data)\n",
        "test_data_svd=svdFeatures(test_data)\n",
        "print(train_data_svd.shape)\n",
        "print(test_data_svd.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "train_data :  (21000, 28, 28)\n",
            "train_labels :  (21000,)\n",
            "test_data :  (9000, 28, 28)\n",
            "test_labels :  (9000,)\n",
            "train_data:  (21000, 28, 28)\n",
            "test_data:  (9000, 28, 28)\n",
            "train_data_flat:  (21000, 784)\n",
            "test_data_flat:  (9000, 784)\n",
            "(21000, 784)\n",
            "(9000, 784)\n",
            "(21000, 28)\n",
            "(9000, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FEWu0iV03vP"
      },
      "source": [
        "#By using data preprocessed with NORMALIZATION FUNCTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FU0ztoOgrEL",
        "outputId": "c859cfab-650a-416c-fa3f-7207b7ddebf5"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "gnb1 = GaussianNB()\n",
        "train = gnb1.fit(train_data_flat_t, train_labels)\n",
        "\n",
        "\n",
        "y_pred1 = gnb1.predict(test_data_flat_t)\n",
        "score1 = gnb1.score(test_data_flat_t, test_labels)\n",
        "print(\"score\", score1)\n",
        "\n",
        "Confusion_Matrix1 = metrics.confusion_matrix(test_labels, y_pred1)\n",
        "print(\"Confusion Matrix\",Confusion_Matrix1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score 0.18744444444444444\n",
            "Confusion Matrix [[  3   0   0   0   0   0 862   0  35   0]\n",
            " [  0   0   0   0   0   0 898   0   2   0]\n",
            " [  0   0   0   0   0   0 881   0  19   0]\n",
            " [  0   0   0   0   0   0 895   0   5   0]\n",
            " [  0   0   0   0   0   0 893   0   7   0]\n",
            " [  0   0   0   0   0   0 222   0 677   1]\n",
            " [  2   0   0   0   0   0 852   0  46   0]\n",
            " [  0   0   0   0   0   0  27   0 873   0]\n",
            " [  0   0   0   0   0   0 221   0 679   0]\n",
            " [  1   0   0   0   0   0  42   0 704 153]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWUb-oZ-09Z6"
      },
      "source": [
        "#By using data preprocessed with PCA "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NxhZTL2hIHm",
        "outputId": "c5b33197-2581-4a97-9f08-648186cea71d"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "gnb2 = GaussianNB()\n",
        "train = gnb2.fit(train_data_pca, train_labels)\n",
        "\n",
        "\n",
        "y_pred2 = gnb2.predict(test_data_pca)\n",
        "score2 = gnb2.score(test_data_pca, test_labels)\n",
        "print(\"score\", score2)\n",
        "\n",
        "Confusion_Matrix2 = metrics.confusion_matrix(test_labels, y_pred2)\n",
        "print(\"Confusion Matrix\",Confusion_Matrix2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score 0.37733333333333335\n",
            "Confusion Matrix [[ 80 179 206 113  48  52 110   8  97   7]\n",
            " [  6 725  14 117   4  16   2   0  10   6]\n",
            " [ 21 248 180  70 209  34  72   2  51  13]\n",
            " [ 14 323   7 344  70  93  21   0  27   1]\n",
            " [  5 120 116 105 419  31  52   0  33  19]\n",
            " [  3  11  11  40  15 423  14 263 112   8]\n",
            " [ 29 215 116  60 154  65 104   1 137  19]\n",
            " [  0  88  51   5  33 148  20 542   0  13]\n",
            " [  3  11  42  22  84 121  29   1 511  76]\n",
            " [  6   3 153   0  52 171 154  98 195  68]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJKNrmU41BQE"
      },
      "source": [
        "#By using data preprocessed with SVD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTeDIb8Zhslp",
        "outputId": "dd692bf3-6034-438c-bae3-3b73b646ff2e"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "gnb3 = GaussianNB()\n",
        "train = gnb3.fit(train_data_svd, train_labels)\n",
        "\n",
        "\n",
        "y_pred3 = gnb3.predict(test_data_svd)\n",
        "score3 = gnb3.score(test_data_svd, test_labels)\n",
        "print(\"score\", score3)\n",
        "\n",
        "Confusion_Matrix3 = metrics.confusion_matrix(test_labels, y_pred3)\n",
        "print(\"Confusion Matrix\",Confusion_Matrix3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score 0.3194444444444444\n",
            "Confusion Matrix [[ 99 217  17 148  97  13  15 186  27  81]\n",
            " [  2 836   0   2   2   1   1  51   1   4]\n",
            " [ 26 101 123 206 151  16  13 186  22  56]\n",
            " [  5 552   2  46  24  15   4 215   3  34]\n",
            " [ 15  85  49 145 336  16  10 159  18  67]\n",
            " [  2 208   0   0   7 175   2 332  11 163]\n",
            " [ 59  98  66 156 182  53  20 129  44  93]\n",
            " [  0 277   0   1   1   3   0 545   0  73]\n",
            " [ 28 136  23  64  97  40   9 199 141 163]\n",
            " [ 18   4   0   2  13  24   2 264  19 554]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}